{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook for VFL-GLM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example notebook that demonstrates using an AWS task runner to run a PRL session to determine overlap, followed by a VFL-GLM session (logistic), and an example using the Tweedie Regression.  \n",
    "\n",
    "For details about required setup and configuration for task runners, see [Using integrate.ai](https://documentation.integrateai.net/#using-integrate-ai)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Set environment variables (or replace inline) with your IAI credentials\n",
    "Generate and manage this token in the UI, in the Tokens page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "IAI_TOKEN = \"\"\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Download the sample data\n",
    "\n",
    "You can download sample data from the integrate.ai sample bucket:\n",
    "\n",
    "For PRL and VFL: [https://s3.ca-central-1.amazonaws.com/public.s3.integrate.ai/integrate_ai_examples/vfl.zip](https://s3.ca-central-1.amazonaws.com/public.s3.integrate.ai/integrate_ai_examples/vfl.zip)\n",
    "\n",
    "### Create a task runner in your workspace\n",
    "\n",
    "For instructions for how to create an AWS task runner, [see the documentation](https://documentation.integrateai.net/#create-an-aws-task-runner). \n",
    "\n",
    "### Upload the sample data to the S3 bucket created for your task runner\n",
    "\n",
    "**Important: By default the task runner expects your data to be in the bucket that was created when the task runner was provisioned.**\n",
    "\n",
    "This bucket name takes the form of: `s3://{aws_traskrunner_profile}-{aws_taskrunner_name}.integrate.ai`\n",
    "\n",
    "For example: `myworkspace-mytaskrunner.integrate.ai`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_taskrunner_profile = \"staging\" # This is your workspace name\n",
    "aws_taskrunner_name = \"shay911\" # Task runner name - must match what was supplied in UI to create task runner\n",
    "\n",
    "base_aws_bucket = f'{aws_taskrunner_profile}-{aws_taskrunner_name}.integrate.ai'\n",
    "\n",
    "base_aws_bucket #Prints the base_aws_bucket name for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the sample datasets\n",
    "\n",
    "For instructions for how to register datasets, [see the documentation](https://documentation.integrateai.net/#register-a-dataset-aws). \n",
    "\n",
    "**In your workspace, register the sample datasets with your task runner with the following names. Replace {base_aws_bucket} with the bucket name for your environment.**\n",
    "\n",
    "active_train = s3://{base_aws_bucket}/vfl/active_train.parquet\n",
    "\n",
    "passive_train = s3://{base_aws_bucket}/vfl/passive_train.parquet\n",
    "\n",
    "active_test = s3://{base_aws_bucket}/vfl/active_test.parquet\n",
    "\n",
    "passive_test = s3://{base_aws_bucket}/vfl/passive_test.parquet\n",
    "\n",
    "\n",
    "**Note:** If you use other datasets or change the names, you **must** update the dataset names in the code example below to run a session succesfully. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the taskbuilder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.taskbuilder.integrate_ai import IntegrateAiTaskBuilder\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "\n",
    "iai_tb_aws = IntegrateAiTaskBuilder(client=client,\n",
    "   task_runner_id=aws_taskrunner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create a PRL Session for linking two or more datasets\n",
    "\n",
    "To create a PRL session, specify a `dataset_config` dictionary indicating the client names and columns to use as identifiers to link the datasets to each other. The number of expected clients will be inferred as the number of items in dataset_config (i.e., two). These client names are referenced for the compute on the PRL session and for any sessions that use the PRL session downstream.\n",
    "\n",
    "For this session, two clients are going to be providing data. Client 1 and client 2 are naming their clients client_1 and client_2 respectively. Their datasets will be linked by the \"id\" column in any provided datasets.\n",
    "\n",
    "Detailed information about PRL is available in the [documentation](https://documentation.integrateai.net/#private-record-linkage-prl-sessions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify PRL dataset configuration \n",
    "\n",
    "prl_data_config = {\n",
    "    \"clients\": {\n",
    "        \"active_client\": {\"id_columns\": [\"id\"]},\n",
    "        \"passive_client\": {\"id_columns\": [\"id\"]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start PRL session\n",
    "\n",
    "prl_session = client.create_prl_session(\n",
    "    name=\"Testing notebook - VFL GLM\",\n",
    "    description=\"I am testing PRL for VFL GLM\",\n",
    "    data_config=prl_data_config,\n",
    ").start()\n",
    "\n",
    "prl_session.id #Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task group with one task for each of the clients joining the session\n",
    "\n",
    "prl_task_group = (SessionTaskGroup(prl_session)\\\n",
    "    .add_task(iai_tb_aws.prl(train_path=active_train_path, test_path=active_test_path, client_name=\"active_client\"))\\\n",
    "    .add_task(iai_tb_aws.prl(train_path=passive_train_path, test_path=passive_test_path, client_name=\"passive_client\"))\n",
    ")\n",
    "\n",
    "prl_task_group_context = prl_task_group.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the status of the task group\n",
    "\n",
    "for i in prl_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "prl_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "prl_task_group_context.wait(60*5, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRL Session Complete!\n",
    "Now you can view the overlap statistics for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "view prl session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "# View PRL session metrics\n",
    "\n",
    "metrics = prl_session.metrics().as_dict()\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a VFL GLM Training Session using the PRL session\n",
    "\n",
    "To create a VFL train session, specify the `prl_session_id` indicating the session you just ran to link the datasets together. \n",
    "\n",
    "For more information about vertical federated learning with a Generalized Linear model (GLM) strategy, see [VFL GLM Model Trianing]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"VflGlm\", \"params\": {}},\n",
    "    \"model\": {\n",
    "        \"passive_client\": {\"params\": {\"input_size\": 7, \"output_activation\": \"sigmoid\"}},\n",
    "        \"active_client\": {\"params\": {\"input_size\": 8, \"output_activation\": \"sigmoid\"}},\n",
    "    },\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"logistic\",\n",
    "        \"params\": {},\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "        \"passive_client\": {\n",
    "            \"label_client\": False,\n",
    "            \"predictors\": [\"x1\", \"x3\", \"x5\", \"x7\", \"x9\", \"x11\", \"x13\"],\n",
    "            \"target\": None,\n",
    "        },\n",
    "        \"active_client\": {\n",
    "            \"label_client\": True,\n",
    "            \"predictors\": [\"x0\", \"x2\", \"x4\", \"x6\", \"x8\", \"x10\", \"x12\", \"x14\"],\n",
    "            \"target\": \"y\",\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vfl_mode` must be set to `train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start a VFL training session\n",
    "\n",
    "vfl_train_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL GLM Train\",\n",
    "    description=\"I am testing VFL GLM training session creation through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    vfl_mode='train',\n",
    "    min_num_clients=2,\n",
    "    num_rounds=2,\n",
    "    package_name=\"iai_glm\",\n",
    "    data_config=data_config,\n",
    "    model_config=model_config\n",
    ").start()\n",
    "\n",
    "\n",
    "vfl_train_session.id   #Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the storage path for the training output.\n",
    "\n",
    "storage_path = f\"{aws_storage_path}/vfl/{vfl_train_session.id}\"\n",
    "\n",
    "# Create and start a task group with one task for each of the clients joining the session\n",
    "# This example uses registered dataset names. \n",
    "\n",
    "vfl_task_group_context = (SessionTaskGroup(vfl_train_session)\\\n",
    "    .add_task(iai_tb_aws.vfl_train(train_path=active_train_path, \n",
    "                                    test_path=active_test_path, \n",
    "                                    batch_size=1024,\n",
    "                                    client_name=\"active_client\", \n",
    "                                    storage_path=aws_storage_path))\\\n",
    "    .add_task(iai_tb_aws.vfl_train(train_path=passive_train_path, \n",
    "                                    test_path=passive_test_path, \n",
    "                                    batch_size=1024, \n",
    "                                    client_name=\"passive_client\", \n",
    "                                    storage_path=aws_storage_path))\\\n",
    "    .start())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the tasks\n",
    "\n",
    "for i in vfl_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "vfl_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "vfl_task_group_context.wait(60*8, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VFL Session Complete!\n",
    "Now you can view and plot the VFL training metrics and start making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = vfl_train_session.metrics().as_dict()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vfl_train_session.metrics().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Prediction on the trained VFL model\n",
    "\n",
    "To create a VFL predict session, specify the `prl_session_id` indicating the session you ran to link the datasets together. You also need the `training_id` of the VFL train session that was run using the same `prl_session_id`. \n",
    "\n",
    "The `vfl_mode` must be set to `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start a VFL predict session\n",
    "\n",
    "vfl_predict_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL-GLM Predict\",\n",
    "    description=\"I am testing VFL-GLM prediction session creation through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    training_session_id=vfl_train_session.id,\n",
    "    vfl_mode=\"predict\",\n",
    "    data_config=data_config,\n",
    ").start()\n",
    "\n",
    "vfl_predict_session.id  # Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the storage path for the output of the prediction session.\n",
    "\n",
    "vfl_predict_task_group_context = (SessionTaskGroup(vfl_predict_session)\\\n",
    "\n",
    "# Create and start a task group with one task for each of the clients joining the session\n",
    "\n",
    ".add_task(iai_tb_aws.vfl_predict(\n",
    "        client_name=\"active_client\", \n",
    "        dataset_path=active_test_path, \n",
    "        raw_output=True,\n",
    "        batch_size=1024, \n",
    "        storage_path=vfl_predict_active_storage_path))\\\n",
    ".add_task(iai_tb_aws.vfl_predict(\n",
    "        client_name=\"passive_client\",\n",
    "        dataset_path=passive_test_path,\n",
    "        batch_size=1024,\n",
    "        raw_output=True,\n",
    "        storage_path=vfl_predict_passive_storage_path))\\\n",
    ".start())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the tasks\n",
    "\n",
    "for i in vfl_predict_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "vfl_predict_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "vfl_predict_task_group_context.wait(60*8, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VFL Predict Session Complete!\n",
    "\n",
    "Now you can view the VFL predictions and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the metrics\n",
    "\n",
    "metrics = vfl_predict_session.metrics().as_dict()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presigned_result_urls = vfl_predict_session.prediction_result()\n",
    "\n",
    "print(vfl_predict_active_storage_path)\n",
    "df_pred = pd.read_csv(presigned_result_urls.get(vfl_predict_active_storage_path))\n",
    "\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a VFL GLM training session using the Tweedie Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended `output_activation` is `None` for `power <= 0` and `exp` for `power > 0`. This is the same as for the sklearn [TweedieRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.TweedieRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"VflGlm\", \"params\": {}},\n",
    "    \"model\": {\n",
    "        \"passive_client\": {\"params\": {\"input_size\": 7, \"output_activation\": None}},\n",
    "        \"active_client\": {\"params\": {\"input_size\": 8, \"output_activation\": None}},\n",
    "    },\n",
    "    \"ml_task\": {\n",
    "        \"type\": \"tweedie\",\n",
    "        \"params\": {\"power\": 0},\n",
    "    },\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.01, \"momentum\": 0.0}},\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "        \"passive_client\": {\n",
    "            \"label_client\": False,\n",
    "            \"predictors\": [\"x1\", \"x3\", \"x5\", \"x7\", \"x9\", \"x11\", \"x13\"],\n",
    "            \"target\": None,\n",
    "        },\n",
    "        \"active_client\": {\n",
    "            \"label_client\": True,\n",
    "            \"predictors\": [\"x0\", \"x2\", \"x4\", \"x6\", \"x8\", \"x10\", \"x12\", \"x14\"],\n",
    "            \"target\": \"y\",\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start a VFL training session\n",
    "\n",
    "tweedie_train_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL GLM Train with Tweedie\",\n",
    "    description=\"I am testing VFL GLM training session creation through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    vfl_mode='train',\n",
    "    min_num_clients=2,\n",
    "    num_rounds=2,\n",
    "    package_name=\"iai_glm\",\n",
    "    data_config=data_config,\n",
    "    model_config=model_config\n",
    ").start()\n",
    "\n",
    "tweedie_train_session.id    #Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the storage path for the training output.\n",
    "\n",
    "storage_path = f\"{aws_storage_path}/vfl/{tweedie_train_session.id}\"\n",
    "\n",
    "# Create and start a task group with one task for each of the clients joining the session\n",
    "# This example uses registered dataset names. \n",
    "\n",
    "tweedie_task_group_context = (SessionTaskGroup(tweedie_train_session)\\\n",
    "    .add_task(iai_tb_aws.vfl_train(train_path=active_train_path, \n",
    "                                    test_path=active_test_path, \n",
    "                                    batch_size=1024,\n",
    "                                    client_name=\"active_client\", \n",
    "                                    storage_path=aws_storage_path))\\\n",
    "    .add_task(iai_tb_aws.vfl_train(train_path=passive_train_path, \n",
    "                                    test_path=passive_test_path, \n",
    "                                    batch_size=1024, \n",
    "                                    client_name=\"passive_client\", \n",
    "                                    storage_path=aws_storage_path))\\\n",
    "    .start())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the tasks\n",
    "\n",
    "for i in tweedie_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "tweedie_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "tweedie_task_group_context.wait(60*5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VFL Session Complete!\n",
    "Now you can view and plot the VFL training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tweedie_train_session.metrics().as_dict()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tweedie_train_session.metrics().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f8223dd0c77fd300f5027a07540ab82ef7f159d3d8a00663aa8a0c2ca691ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
