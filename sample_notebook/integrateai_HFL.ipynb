{"cells":[{"cell_type":"markdown","metadata":{},"source":["# integrate.ai API Sample Notebook to run HFL tasks with an AWS task runner.\n"]},{"cell_type":"markdown","metadata":{},"source":["This is an example notebook that demonstrates creating taskbuilders and running tasks using an AWS task runner. \n","For details about required setup and configuration for task runners, see [Using integrate.ai](https://documentation.integrateai.net/#using-integrate-ai)."]},{"cell_type":"markdown","metadata":{},"source":["## Setup\n","### Set environment variables (or replace inline) with your IAI credentials\n","Generate and manage this token in the UI, in the Tokens page. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from integrate_ai_sdk.api import connect\n","import os\n","import json\n","import pandas as pd\n","\n","IAI_TOKEN = \"\"\n","client = connect(token=IAI_TOKEN)"]},{"cell_type":"markdown","metadata":{},"source":["The documentation section [Understanding Models](https://documentation.integrateai.net/#understanding-models) provides additional context into the parameters that are used during training session creation.<br />\n","For this session we are going to be using two training clients and two rounds. \n","\n","You can find the model config and data schema details in the documentation."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Specify the model and data configurations\n","\n","model_config = {\n","    \"experiment_name\": \"test_synthetic_tabular\",\n","    \"experiment_description\": \"test_synthetic_tabular\",\n","    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n","    \"model\": {\"params\": {\"input_size\": 15, \"hidden_layer_sizes\": [6, 6, 6], \"output_size\": 2}},\n","    \"balance_train_datasets\": False,\n","    \"ml_task\": {\n","        \"type\": \"classification\",\n","        \"params\": {\n","            \"loss_weights\": None,\n","        },\n","    },\n","    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.2, \"momentum\": 0.0}},\n","    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n","    \"save_best_model\": {\n","        \"metric\": \"loss\",  # to disable this and save model from the last round, set to None\n","        \"mode\": \"min\",\n","    },\n","    \"seed\": 23,  # for reproducibility\n","}\n","\n","data_schema = {\n","    \"predictors\": [\"x0\", \"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\", \"x7\", \"x8\", \"x9\", \"x10\", \"x11\", \"x12\", \"x13\", \"x14\"],\n","    \"target\": \"y\",\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create and start the training session\n","\n","hfl_session = client.create_fl_session(\n","    name=\"Testing notebook - HFL\",\n","    description=\"I am testing session creation with a task runner through a notebook\",\n","    min_num_clients=2,\n","    num_rounds=2,\n","    package_name=\"iai_ffnet\",\n","    model_config=model_config,\n","    data_config=data_schema\n",").start()\n","\n","hfl_session.id # Prints the training session ID for reference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a task group with one task for each of the clients joining the session\n","# This example uses registered dataset names\n","\n","task_group = (\n","    SessionTaskGroup(hfl_session)\n","    .add_task(iai_tb_aws.hfl(train_dataset_name=\"train_one\", test_dataset_name=\"test_parquet\", use_gpu=False))\\\n","    .add_task(iai_tb_aws.hfl(train_dataset_name=\"train_two\", test_dataset_name=\"test_parquet\", use_gpu=False))\n",")\n","\n","task_group_context = task_group.start()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Monitor the submitted tasks\n","\n","for i in task_group_context.contexts.values():\n","    print(json.dumps(i.status(), indent=4))\n","\n","task_group_context.monitor_task_logs()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Wait for the tasks to complete (success = True)\n","\n","task_group_context.wait(60*8, 2)"]},{"cell_type":"markdown","metadata":{},"source":["### HFL Session Complete!\n","Now you can view the training metrics and start making predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrieve the session metrics\n","\n","hfl_session.metrics().as_dict()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the session metrics\n","\n","fig = hfl_session.metrics().plot()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hfl_gbm = hfl_session.id()\n"," training_session.model().as_sklearn()"]},{"cell_type":"markdown","metadata":{},"source":["# Task 2: Create a linear inference session (HFL)"]},{"cell_type":"markdown","metadata":{},"source":["The built-in model package `iai_linear_inference` trains a bundle of linear models for the target of interest against a specified list of predictors. It obtains the coefficients and variance estimates, and also calculates the p-values from the corresponding hypothesis tests. Linear inference is particularly useful for genome-wide association studies (GWAS), to identify genomic variants that are statistically associated with a risk for a disease or a particular trait.\n","\n","This is a horizontal federated learning (HFL) model package.\n","\n","For more information, see the [documentation](https://documentation.integrateai.net/#linear-inference-sessions)."]},{"cell_type":"markdown","metadata":{},"source":["### Sample model config and data config\n","To be compatible with the `iai_linear_inference` package, we use the strategy `LogitRegInference` in the `model_config`, if the target of interest is binary, and use `LinearRegInference` if it is continuous.\n","\n","The `data_config` dictionary should include the following 3 fields (note that the columns in all the fields can be specified as either names/strings or indices/integers):\n","- `target`: the target column of interest;\n","- `shared_predictors`: predictor columns that should be included in all linear models (e.g., the confounding factors like age, gender in GWAS);\n","- `chunked_predictors`: predictor columns that should be included in the linear model one at a time (e.g., the gene expressions in GWAS)\n","\n","With the example data config below, the session will train 4 logistic regression models with `y` as the target, and `x1, x2` plus any one of `x0, x3, x10, x11` as predictors."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Specify the model and data configurations\n","\n","model_config_logit = {\n","    \"strategy\": {\"name\": \"LogitRegInference\", \"params\": {}},\n","    \"seed\": 23,  # for reproducibility\n","}\n","\n","data_config_logit = {\n","    \"target\": \"y\",\n","    \"shared_predictors\": [\"x1\", \"x2\"],\n","    \"chunked_predictors\": [\"x0\", \"x3\", \"x10\", \"x11\"]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create and start a linear inference session \n","\n","training_session_logit = client.create_fl_session(\n","    name=\"Testing linear inference session\",\n","    description=\"I am testing linear inference session creation using a task runner through a notebook\",\n","    min_num_clients=2,\n","    num_rounds=5,\n","    package_name=\"iai_linear_inference\",\n","    model_config=model_config_logit,\n","    data_config=data_config_logit\n",").start()\n","\n","training_session_logit.id"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a task group\n","# This example uses registered dataset names\n","\n","task_group_context = (\n","    SessionTaskGroup(training_session_logit)\n","    .add_task(iai_tb_aws.hfl(train_dataset_name=\"train_one\", test_dataset_name=\"test_parquet\"))\\\n","    .add_task(iai_tb_aws.hfl(train_dataset_name=\"train_two\", test_dataset_name=\"test_parquet\"))\n","    .start()\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check the status of the tasks\n","\n","for i in task_group_context.contexts.values():\n","    print(json.dumps(i.status(), indent=4))\n","task_group_context.monitor_task_logs()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Wait for the tasks to complete (success = True)\n","\n","task_group_context.wait(60*5, 2)"]},{"cell_type":"markdown","metadata":{},"source":["## Inference Session Complete!\n","Now we can view the training metrics and model details such as the model coefficients and p-values. Note that since there are a bundle of models being trained, the metrics below are the average values of all the models."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_session_logit.metrics().as_dict()\n","training_session_logit.metrics().plot()"]},{"cell_type":"markdown","metadata":{},"source":["### Trained models are accessible from the completed session\n","\n","The `LinearInferenceModel` object can be retrieved using the model's `as_pytorch` method. And the relevant information such as p-values can be accessed directly from the model object.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_logit = training_session_logit.model().as_pytorch()\n","pv = model_logit.p_values()\n","pv"]},{"cell_type":"markdown","metadata":{},"source":["The `.summary` method fetches the coefficient, standard error and p-value of the model corresponding to the specified predictor."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["summary_x0 = model_logit.summary(\"x0\")\n","summary_x0"]},{"cell_type":"markdown","metadata":{},"source":["It is also possible to make predictions with the resulting bundle of models, when the data is loaded by the `ChunkedTabularDataset` from the `iai_linear_inference` package. For an example of this, see the `integrateai_linear_inference.ipynb` see the [documentation](https://documentation.integrateai.net/#making-predictions-from-a-linear-inference-session)."]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
