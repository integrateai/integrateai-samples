{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai HFL Linear Inference Sample Notebook\n",
    "\n",
    "In this notebook, we will train an HFL session with the built-in package `iai_linear_inference` which trains a bundle of linear models for the target of interest against a specified list of predictors, obtains the coefficients and variance estimates, and also calculates the p-values from the corresponding hypothesis tests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI credentials\n",
    "### Generate and manage this token in the UI, in the Tokens page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model config and data config\n",
    "To be compatible with the `iai_linear_inference` package, we use the strategy `LogitRegInference` in the `model_config`, if the target of interest is binary, and use `LinearRegInference` if it is continuous.\n",
    "\n",
    "The `data_config` dictionary should include the following 3 fields (note that the columns in all the fields can be specified as either names/strings or indices/integers):\n",
    "- `target`: the target column of interest;\n",
    "- `shared_predictors`: predictor columns that should be included in all linear models (e.g., the confounding factors like age, gender in GWAS);\n",
    "- `chunked_predictors`: predictor columns that should be included in the linear model one at a time (e.g., the gene expressions in GWAS)\n",
    "\n",
    "With the example data config below, the session will train 4 logistic regression models with `y` as the target, and `x1, x2` plus any one of `x0, x3, x10, x11` as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "assign schemas"
    ]
   },
   "outputs": [],
   "source": [
    "model_config_logit = {\n",
    "    \"strategy\": {\"name\": \"LogitRegInference\", \"params\": {}},\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}\n",
    "\n",
    "data_config_logit = {\n",
    "    \"target\": \"y\",\n",
    "    \"shared_predictors\": [\"x1\", \"x2\"],\n",
    "    \"chunked_predictors\": [\"x0\", \"x3\", \"x10\", \"x11\"]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Session\n",
    "\n",
    "The documentation for [creating a session](https://documentation.integrateai.net/#create-and-start-the-training-session) gives a bit more context into the parameters that are used during training session creation.<br />\n",
    "For this session we are going to be using 2 training clients and 5 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start session"
    ]
   },
   "outputs": [],
   "source": [
    "training_session_logit = client.create_fl_session(\n",
    "    name=\"Testing linear inference session\",\n",
    "    description=\"I am testing linear inference session creation through a notebook\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=5,\n",
    "    package_name=\"iai_linear_inference\",\n",
    "    model_config=model_config_logit,\n",
    "    data_config=data_config_logit,\n",
    ").start()\n",
    "\n",
    "training_session_logit.id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a training session using iai client\n",
    "Make sure that the sample data you [downloaded](https://documentation.integrateai.net/#review-the-sample-model-configuration) is saved to your `~/Downloads` directory, otherwise update the `data_path` below to point to the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/Downloads/synthetic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start docker clients"
    ]
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "client_1 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {training_session_logit.id} --train-path {data_path}/train_silo0.parquet --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-1-inference --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    universal_newlines=True\n",
    ")\n",
    "\n",
    "client_2 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {training_session_logit.id} --train-path {data_path}/train_silo1.parquet --test-path {data_path}/test.parquet --batch-size 1024 --client-name client-2-inference --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    universal_newlines=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poll for session status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "poll for session status"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_round = None\n",
    "current_status = None\n",
    "while client_1.poll() is None or client_2.poll() is None:\n",
    "    output1 = client_1.stdout.readline().strip()\n",
    "    output2 = client_2.stdout.readline().strip()\n",
    "    if output1:\n",
    "        print(\"silo1: \", output1)\n",
    "    if output2:\n",
    "        print(\"silo2: \", output2)\n",
    "\n",
    "    # poll for status and round\n",
    "    if current_status != training_session_logit.status:\n",
    "        print(\"Session status: \", training_session_logit.status)\n",
    "        current_status = training_session_logit.status\n",
    "    if current_round != training_session_logit.round and training_session_logit.round > 0:\n",
    "        print(\"Session round: \", training_session_logit.round)\n",
    "        current_round = training_session_logit.round\n",
    "    time.sleep(1)\n",
    "\n",
    "output1, error1 = client_1.communicate()\n",
    "output2, error2 = client_2.communicate()\n",
    "\n",
    "print(\n",
    "    \"client_1 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_1.returncode, output1, error1)\n",
    ")\n",
    "print(\n",
    "    \"client_2 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_2.returncode, output2, error2)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "Now we can view the training metrics and model details such as the model coefficients and p-values. Note that since there are a bundle of models being trained, the metrics below are the average values of all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "view session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "training_session_logit.metrics().as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_session_logit.metrics().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained models are accessible from the completed session\n",
    "\n",
    "The `LinearInferenceModel` object can be retrieved using the model's `as_pytorch` method. And the relevant information such as p-values can be accessed directly from the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "get model"
    ]
   },
   "outputs": [],
   "source": [
    "model_logit = training_session_logit.model().as_pytorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "get pvalues"
    ]
   },
   "outputs": [],
   "source": [
    "pv = model_logit.p_values()\n",
    "pv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.summary` method fetches the coefficient, standard error and p-value of the model corresponding to the specified predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "get summary"
    ]
   },
   "outputs": [],
   "source": [
    "summary_x0 = model_logit.summary(\"x0\")\n",
    "summary_x0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to make predictions with the resulting bundle of models, when the data is loaded by the `ChunkedTabularDataset` from the `iai_linear_inference` package. Note that the predictions will be of shape `(n_samples, n_chunked_predictors)` where each column corresponds to one model from the bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "make predictions"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from integrate_ai_sdk.packages.LinearInference.dataset import ChunkedTabularDataset\n",
    "\n",
    "\n",
    "ds = ChunkedTabularDataset(path=f\"{data_path}/test.parquet\", **data_config_logit)\n",
    "dl = DataLoader(ds, batch_size=len(ds), shuffle=False)\n",
    "x = torch.tensor(ds.X)\n",
    "y_pred = model_logit(x)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_sdk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
