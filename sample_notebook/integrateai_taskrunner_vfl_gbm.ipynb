{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# integrate.ai API Sample Notebook for VFL-GBM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example notebook that demonstrates creating using an AWS task runner to run a VFL-GBM session. It also demonstrates two PRL sessions with different match thresholds. \n",
    "\n",
    "For details about required setup and configuration for task runners, see [Using integrate.ai](https://documentation.integrateai.net/#using-integrate-ai)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Set environment variables (or replace inline) with your IAI credentials\n",
    "Generate and manage this token in the UI, in the Tokens page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")\n",
    "client = connect(token=IAI_TOKEN)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your AWS variables\n",
    "\n",
    "**Important: The task runner expects your data to be in the bucket that was created when the task runner was provisioned.**\n",
    "\n",
    "This bucket name takes the form of: `s3://{aws_taskrunner_profile}-{aws_taskrunner_name}.integrate.ai`\n",
    "\n",
    "For example: `myworkspace-mytaskrunner.integrate.ai`\n",
    "\n",
    "You can download sample data from the integrate.ai sample bucket [s3://public.s3.integrate.ai/integrate_ai_examples/vfl/](s3://public.s3.integrate.ai/integrate_ai_examples/vfl/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_taskrunner_profile = \"<myworkspace>\" # This is your workspace name\n",
    "aws_taskrunner_name = \"<mytaskrunner>\" # Task runner name - must match what was supplied in UI to create task runner\n",
    "\n",
    "base_aws_bucket = f'{aws_taskrunner_profile}-{aws_taskrunner_name}.integrate.ai'\n",
    "\n",
    "# Example datapaths. Make sure that the data you want to work with exists in the base_aws_bucket for your task runner.\n",
    "# HFL datapaths\n",
    "train_path1 = f's3://{base_aws_bucket}/synthetic/train_silo0.parquet'\n",
    "test_path1 = f's3://{base_aws_bucket}/synthetic/test.parquet'\n",
    "train_path2 = f's3://{base_aws_bucket}/synthetic/train_silo1.parquet'\n",
    "test_path2 = f's3://{base_aws_bucket}/synthetic/test.parquet'\n",
    "\n",
    "#EDA/PRL/VFL datapaths\n",
    "active_train_path = f's3://{base_aws_bucket}/synthetic_prl_vfl/active_train.parquet'\n",
    "active_test_path = f's3://{base_aws_bucket}/synthetic_prl_vfl/active_test.parquet'\n",
    "passive_train_path = f's3://{base_aws_bucket}/synthetic_prl_vfl/passive_train.parquet'\n",
    "passive_test_path = f's3://{base_aws_bucket}/synthetic_prl_vfl/passive_test.parquet'\n",
    "\n",
    "#Where to store the trained model\n",
    "aws_storage_path = f's3://{base_aws_bucket}/model'\n",
    "\n",
    "#Where to store VFL predictions - must be full path and file name\n",
    "vfl_predict_active_storage_path = f's3://{base_aws_bucket}/vfl_predict/active_predictions.csv'\n",
    "vfl_predict_passive_storage_path = f's3://{base_aws_bucket}/vfl_predict/passive_predictions.csv'\n",
    "\n",
    "base_aws_bucket #Prints the base_aws_bucket name for reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the taskbuilder \n",
    "\n",
    "Specify the task runner name (e.g. `mytaskrunner`) as `task_runner_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import integrate_ai_sdk\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder.integrate_ai import IntegrateAiTaskBuilder\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder import taskrunner_context\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder.integrate_ai import IntegrateAiTaskBuilder\n",
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "\n",
    "iai_tb_aws = IntegrateAiTaskBuilder(client=client,\n",
    "   task_runner_id=aws_taskrunner_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create a PRL Session for linking two or more datasets\n",
    "\n",
    "To create a PRL session, specify a `dataset_config` dictionary indicating the client names and columns to use as identifiers to link the datasets to each other. The number of expected clients will be inferred as the number of items in dataset_config (i.e., two). These client names are referenced for the compute on the PRL session and for any sessions that use the PRL session downstream.\n",
    "\n",
    "For this session, two clients are going to be providing data. Client 1 and client 2 are naming their clients client_1 and client_2 respectively. Their datasets will be linked by the \"id\" column in any provided datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "create prl data config"
    ]
   },
   "outputs": [],
   "source": [
    "# Specify PRL dataset configuration \n",
    "\n",
    "prl_data_config = {\n",
    "    \"clients\": {\n",
    "        \"active_client\": {\"id_columns\": [\"id\"]},\n",
    "        \"passive_client\": {\"id_columns\": [\"id\"]},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "create prl session"
    ]
   },
   "outputs": [],
   "source": [
    "# Create and start PRL session\n",
    "\n",
    "prl_session = client.create_prl_session(\n",
    "    name=\"Testing notebook - VFL GBM\",\n",
    "    description=\"I am testing PRL for VFL GBM\",\n",
    "    data_config=prl_data_config,\n",
    "    startup_mode=\"external\"\n",
    ").start()\n",
    "\n",
    "prl_session.id #Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start prl training batch clients"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a task group with one task for the server, and one for each of the clients joining the session\n",
    "\n",
    "task_group = (SessionTaskGroup(prl_session)\\\n",
    ".add_task(iai_tb_aws.fls(storage_path=aws_storage_path))\\\n",
    ".add_task(iai_tb_aws.prl(train_path=active_train_path, test_path=active_test_path, client_name=\"active_client\"))\\\n",
    ".add_task(iai_tb_aws.prl(train_path=passive_train_path, test_path=passive_test_path, client_name=\"passive_client\"))\n",
    ")\n",
    "\n",
    "task_group_context = task_group.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the status of the task group\n",
    "import json\n",
    "\n",
    "for i in task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "task_group_context.wait(60*5, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRL Session Complete!\n",
    "Now you can view the overlap stats for the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "view prl session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "# View PRL session metrics\n",
    "\n",
    "metrics = prl_session.metrics().as_dict()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRL Session With Different Match Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with a different match threshold\n",
    "\n",
    "prl_match_threshold_session = client.create_prl_session(\n",
    "    name=\"Testing notebook - PRL\",\n",
    "    description=\"I am testing PRL session creation through a notebook\",\n",
    "    data_config=prl_data_config,\n",
    "    match_threshold=0.5,\n",
    "    startup_mode=\"external\"\n",
    ").start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a task group with one task for the server, and one for each of the clients joining the session\n",
    "\n",
    "task_group = (SessionTaskGroup(prl_match_threshold_session)\\\n",
    ".add_task(iai_tb_aws.fls(storage_path=aws_storage_path))\\\n",
    ".add_task(iai_tb_aws.prl(train_path=active_train_path, test_path=active_test_path, client_name=\"active_client\"))\\\n",
    ".add_task(iai_tb_aws.prl(train_path=passive_train_path, test_path=passive_test_path, client_name=\"passive_client\"))\n",
    ")\n",
    "\n",
    "task_group_context = task_group.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the status of the task group\n",
    "import json\n",
    "\n",
    "for i in task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "task_group_context.wait(60*5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prl_match_threshold_metrics = prl_match_threshold_session.metrics().as_dict()\n",
    "prl_match_threshold_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a VFL GBM Training Session using the PRL session\n",
    "\n",
    "To create a VFL train session, specify the `prl_session_id` indicating the session you just ran to link the datasets together. The `vfl_mode` needs to be set to `train`.\n",
    "\n",
    "For more information about vertical federated learning with a SplitNN model strategy, see [VFL SplitNN Model Trianing](https://documentation.integrateai.net/#vfl-splitnn-model-training). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"VflGbm\", \"params\": {\"hide_intersection\": False}},\n",
    "    \"model\": {\n",
    "        \"params\": {\n",
    "            \"max_depth\": 4,\n",
    "            \"learning_rate\": 0.05,\n",
    "            \"random_state\": 23,\n",
    "            \"max_bins\": 255,\n",
    "        }\n",
    "    },\n",
    "    \"ml_task\": {\"type\": 'classification', \"params\": {}},\n",
    "}\n",
    "\n",
    "data_config = {\n",
    "    \"passive_client\": {\n",
    "        \"label_client\": False,\n",
    "        \"predictors\": [\"x1\", \"x3\", \"x5\", \"x7\", \"x9\", \"x11\", \"x13\"],\n",
    "        \"target\": None,\n",
    "    },\n",
    "    \"active_client\": {\n",
    "        \"label_client\": True,\n",
    "        \"predictors\": [\"x0\", \"x2\", \"x4\", \"x6\", \"x8\", \"x10\", \"x12\", \"x14\"],\n",
    "        \"target\": \"y\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "create training session"
    ]
   },
   "outputs": [],
   "source": [
    "# Create and start a VFL training session\n",
    "\n",
    "vfl_train_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL-GBM training\",\n",
    "    description=\"I am testing VFL GBM training session creation through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    vfl_mode=\"train\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=5,\n",
    "    package_name=\"iai_ffnet\",\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    startup_mode=\"external\"\n",
    ").start()\n",
    "\n",
    "vfl_train_session.id    #Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start training task"
    ]
   },
   "outputs": [],
   "source": [
    "# Create and start a task group with one task for the server, and one for each of the clients joining the session\n",
    "\n",
    "vfl_task_group_context = (SessionTaskGroup(vfl_train_session)\\\n",
    "    .add_task(iai_tb_aws.fls(storage_path=aws_storage_path))\\\n",
    "    .add_task(iai_tb_aws.vfl_train(train_path=active_train_path, \n",
    "                                    test_path=active_test_path, \n",
    "                                    batch_size=1024,  \n",
    "                                    client_name=\"active_client\", \n",
    "                                    storage_path=aws_storage_path))\\\n",
    "    .add_task(iai_tb_aws.vfl_train(train_path=passive_train_path, \n",
    "                                    test_path=passive_test_path, \n",
    "                                    batch_size=1024, \n",
    "                                    client_name=\"passive_client\", \n",
    "                                    storage_path=aws_storage_path))\\\n",
    "    .start())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "check training task session id"
    ]
   },
   "outputs": [],
   "source": [
    "# Check the status of the tasks\n",
    "\n",
    "for i in vfl_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "vfl_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "vfl_task_group_context.wait(60*5, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a: VFL Session Complete!\n",
    "Now you can view the VFL training metrics and start making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "view training metrics"
    ]
   },
   "outputs": [],
   "source": [
    "metrics = vfl_train_session.metrics().as_dict()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = vfl_train_session.metrics().plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b: Make a Prediction on the trained VFL model\n",
    "\n",
    "To create a VFL predict session, specify the `prl_session_id` indicating the session you ran to link the datasets together. You also need the `training_id` of the VFL train session that was run using the same `prl_session_id`. \n",
    "\n",
    "The `vfl_mode` must be set to `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "create predict session"
    ]
   },
   "outputs": [],
   "source": [
    "# Create and start a VFL predict session\n",
    "\n",
    "vfl_predict_session = client.create_vfl_session(\n",
    "    name=\"Testing notebook - VFL Predict\",\n",
    "    description=\"I am testing VFL Predict session creation with an AWS task runner through a notebook\",\n",
    "    prl_session_id=prl_session.id,\n",
    "    training_session_id=vfl_train_session.id,\n",
    "    vfl_mode=\"predict\",\n",
    "    data_config=data_config,\n",
    "    startup_mode=\"external\"\n",
    ").start()\n",
    "\n",
    "vfl_predict_session.id  # Prints the session ID for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "start prediction task"
    ]
   },
   "outputs": [],
   "source": [
    "# Create and start a task group with one task for the server, and one for each of the clients joining the session\n",
    "\n",
    "vfl_predict_task_group_context = (SessionTaskGroup(vfl_predict_session)\\\n",
    ".add_task(iai_tb_aws.fls(storage_path=aws_storage_path))\\\n",
    ".add_task(iai_tb_aws.vfl_predict(\n",
    "        client_name=\"active_client\", \n",
    "        dataset_path=active_test_path, \n",
    "        raw_output=True,\n",
    "        batch_size=1024, \n",
    "        storage_path=vfl_predict_active_storage_path))\\\n",
    ".add_task(iai_tb_aws.vfl_predict(\n",
    "        client_name=\"passive_client\",\n",
    "        dataset_path=passive_test_path,\n",
    "        batch_size=1024,\n",
    "        raw_output=True,\n",
    "        storage_path=vfl_predict_passive_storage_path))\\\n",
    ".start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the tasks\n",
    "\n",
    "for i in vfl_predict_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "vfl_predict_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "vfl_predict_task_group_context.wait(60*5, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b: VFL Predict Session Complete!\n",
    "\n",
    "Now you can view the VFL predictions and evaluate the performance as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "presigned_result_urls = vfl_predict_session.prediction_result()\n",
    "\n",
    "print(vfl_predict_active_storage_path)\n",
    "df_vfl_pred = pd.read_csv(presigned_result_urls.get(vfl_predict_active_storage_path))\n",
    "\n",
    "df_vfl_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f8223dd0c77fd300f5027a07540ab82ef7f159d3d8a00663aa8a0c2ca691ffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
