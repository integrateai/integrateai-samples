{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fb707a",
   "metadata": {},
   "source": [
    "# integrate.ai API LSTM Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19800d30",
   "metadata": {},
   "source": [
    "## Prerequisites:\n",
    "An instance of our docker client, downloaded from the Docker page in the UI  \n",
    "An IAI token, created using the Token Management page in the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf113ca",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f382a1",
   "metadata": {
    "tags": [
     "get access token"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2e7f5",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed09b0",
   "metadata": {
    "tags": [
     "authenticate to client"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a06d29",
   "metadata": {},
   "source": [
    "## Custom model, dataset, and LSTMTagger.json\n",
    "Choose a name for your custom model, and set the path for the model and data configurations.  \n",
    "Note that the name for your custom model **must be unique**.  \n",
    "This means that the name for your custom model cannot already be in the Package Name column of the Custom Models Packages Table in the Model Library Page of the UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the following lines to your package name and model and data configuration paths\n",
    "package_name = \"lstm_sample_package\"\n",
    "model_config_path = \"../lstmTagger/lstmtagger.json\"\n",
    "data_config_path = \"../lstmTagger/taggerDataset.json\"\n",
    "\n",
    "# Update the following lines to your package and dataset paths\n",
    "package_path = \"../lstmTagger\"\n",
    "dataset_path = \"../lstmTagger/sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26e5e8",
   "metadata": {
    "tags": [
     "load configs"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(model_config_path, \"r\") as f:\n",
    "    lstm_model_config = json.load(f)\n",
    "\n",
    "with open(data_config_path, \"r\") as f:\n",
    "    data_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2f008",
   "metadata": {},
   "source": [
    "## Upload customized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e26541",
   "metadata": {
    "tags": [
     "upload model"
    ]
   },
   "outputs": [],
   "source": [
    "client.upload_model(\n",
    "    package_path=package_path,\n",
    "    dataset_path=dataset_path,\n",
    "    package_name=package_name,\n",
    "    sample_model_config_path=model_config_path,\n",
    "    sample_data_config_path=data_config_path,\n",
    "    batch_size=256,\n",
    "    task=\"classification\",\n",
    "    test_only=False,\n",
    "    description=\"A custom LSTM model.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf8183",
   "metadata": {},
   "source": [
    "## Local Taskrunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.taskgroup.base import SessionTaskGroup\n",
    "from integrate_ai_sdk.taskgroup.taskbuilder.local import local_python\n",
    "\n",
    "local_tb = local_python(client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f49e93",
   "metadata": {},
   "source": [
    "## Create a Session\n",
    "\n",
    "The Quickstart guide for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the paramters that are used during session creation.<br />\n",
    "For this session we are going to be using two training clients and two rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2f235",
   "metadata": {
    "tags": [
     "assign model config"
    ]
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n",
    "    \"model\": {\"params\": lstm_model_config},\n",
    "    \"ml_task\": {\"type\": \"classification\", \"params\": {}},\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.9, \"momentum\": 0.9}},\n",
    "    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b491e3",
   "metadata": {
    "tags": [
     "start session"
    ]
   },
   "outputs": [],
   "source": [
    "session = client.create_fl_session(\n",
    "    name=\"LSTM custom model notebook\",\n",
    "    description=\"Training a custom LSTM model using a jupyter notebook.\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=5,\n",
    "    package_name=package_name,\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    ").start()\n",
    "\n",
    "session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b89659",
   "metadata": {},
   "source": [
    "## Start a training session using iai local taskbuilder\n",
    "This example uses a local taskbuilder, so that you can use files in your local environment. If you would like to use data in the cloud use an AWS or Azure taskrunner (as shown in other example notebooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469aed9",
   "metadata": {
    "tags": [
     "start docker clients"
    ]
   },
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "\n",
    "# The path to the data you want to train should be an absolute path to the directory\n",
    "data_path = abspath(dataset_path)\n",
    "\n",
    "# client_1 = subprocess.Popen(\n",
    "#     f\"iai client train --token {IAI_TOKEN} --session {session.id} --train-path {data_path} --test-path {data_path} --batch-size 512 --approve-custom-package --client-name client-1 --remove-after-complete\",\n",
    "#     shell=True,\n",
    "#     stdout=subprocess.PIPE,\n",
    "#     stderr=subprocess.PIPE,\n",
    "# )\n",
    "# client_2 = subprocess.Popen(\n",
    "#     f\"iai client train --token {IAI_TOKEN} --session {session.id} --train-path {data_path} --test-path {data_path} --batch-size 512 --approve-custom-package --client-name client-2 --remove-after-complete\",\n",
    "#     shell=True,\n",
    "#     stdout=subprocess.PIPE,\n",
    "#     stderr=subprocess.PIPE,\n",
    "# )\n",
    "\n",
    "session_task_group_context = (\n",
    "        SessionTaskGroup(session) \\\n",
    "        .add_task(local_tb.hfl(train_path=data_path, test_path=data_path))\\\n",
    "        .add_task(local_tb.hfl(train_path=data_path, test_path=data_path))\\\n",
    "        .start()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427758d8",
   "metadata": {},
   "source": [
    "## Poll for session status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f059b",
   "metadata": {
    "tags": [
     "poll for session status"
    ]
   },
   "outputs": [],
   "source": [
    "# Check the task group status\n",
    "\n",
    "for i in session_task_group_context.contexts.values():\n",
    "    print(json.dumps(i.status(), indent=4))\n",
    "\n",
    "session_task_group_context.monitor_task_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the tasks to complete (success = True)\n",
    "\n",
    "session_task_group_context.wait(60*8, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9bc55",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "\n",
    "You can view the results using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = session.metrics().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48512369",
   "metadata": {},
   "source": [
    "You can view the training metrics via the .metrics() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77099b21",
   "metadata": {
    "tags": [
     "view session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "display(session.metrics().as_dict())  # view all of the training metrics\n",
    "display(session.metrics().federated_metrics)  # view the loss for each round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dcdb91",
   "metadata": {},
   "source": [
    "## Trained model weights are accessible from the completed session\n",
    "Model parameters can be retrieved using the model's state_dict method. These parameters can then be saved using torch.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790d7d8",
   "metadata": {
    "tags": [
     "save model"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = session.model().as_pytorch()\n",
    "\n",
    "save_state_dict_folder = \"./saved_models\"\n",
    "# PyTorch conventional file type\n",
    "file_name = f\"{session.id}.pt\"\n",
    "os.makedirs(save_state_dict_folder, exist_ok=True)\n",
    "saved_state_dict_path = os.path.join(save_state_dict_folder, file_name)\n",
    "\n",
    "with open(saved_state_dict_path, \"w\") as f:\n",
    "    torch.save(model.state_dict(), saved_state_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529be150",
   "metadata": {},
   "source": [
    "## Load the saved model\n",
    "\n",
    "To load a model saved previously, a model object needs to be initialized first. This can be done by directly importing one of the IAI-supported packages (e.g., FFNet) or using the model class defined in a custom package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ab119",
   "metadata": {
    "tags": [
     "load model"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.sample_packages.lstmTagger.model import LSTMTagger\n",
    "\n",
    "model = LSTMTagger(embedding_dim=4, hidden_dim=3, output_size=4, vocab_size=9)\n",
    "\n",
    "# use torch.load to unpickle the state_dict\n",
    "target_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a501f97",
   "metadata": {},
   "source": [
    "## Load the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915c254",
   "metadata": {
    "tags": [
     "create data loader"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.sample_packages.lstmTagger.dataset import TaggerDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = TaggerDataset(path=dataset_path, max_len=5)\n",
    "dl = DataLoader(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4803ed3",
   "metadata": {},
   "source": [
    "## Run predictions using the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ffc78",
   "metadata": {
    "tags": [
     "predict"
    ]
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = torch.tensor([])\n",
    "y_pred = torch.tensor([])\n",
    "for x, y in dl:\n",
    "    y_true = torch.cat((y_true, y))\n",
    "\n",
    "    # The following line calculates the predicted label for a classification problem, and should be modified to fit your needs\n",
    "    pred = model(x).max(dim=1)[1]\n",
    "\n",
    "    y_pred = torch.cat((y_pred, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69c332",
   "metadata": {
    "tags": [
     "show accuracy"
    ]
   },
   "outputs": [],
   "source": [
    "f\"accuracy: {(y_pred == y_true).float().mean().item()}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd2cc32795b80d96a3961ede3063db3c5a4bd611a813fa92794506d052f542db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
