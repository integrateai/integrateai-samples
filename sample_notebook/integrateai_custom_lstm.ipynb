{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fb707a",
   "metadata": {},
   "source": [
    "# integrate.ai API LSTM Sample Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19800d30",
   "metadata": {},
   "source": [
    "## Prerequisites:\n",
    "An instance of our docker client, downloaded from the Docker page in the UI  \n",
    "An IAI token, created using the Token Management page in the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf113ca",
   "metadata": {},
   "source": [
    "## Set environment variables (or replace inline) with your IAI Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f382a1",
   "metadata": {
    "tags": [
     "get access token"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IAI_TOKEN = os.environ.get(\"IAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef2e7f5",
   "metadata": {},
   "source": [
    "## Authenticate to the integrate.ai api client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed09b0",
   "metadata": {
    "tags": [
     "authenticate to client"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.api import connect\n",
    "\n",
    "client = connect(token=IAI_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a06d29",
   "metadata": {},
   "source": [
    "## Custom model, dataset, and LSTMTagger.json\n",
    "Choose a name for your custom model, and set the path for the model and data configurations.  \n",
    "Note that the name for your custom model **must be unique**.  \n",
    "This means that the name for your custom model cannot already be in the Package Name column of the Custom Models Packages Table in the Model Library Page of the UI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c9b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the following lines to your package name and model and data configuration paths\n",
    "package_name = \"lstm_sample_package\"\n",
    "model_config_path = \"../lstmTagger/lstmtagger.json\"\n",
    "data_config_path = \"../lstmTagger/taggerDataset.json\"\n",
    "\n",
    "# Update the following lines to your package and dataset paths\n",
    "package_path = \"../lstmTagger\"\n",
    "dataset_path = \"../lstmTagger/sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26e5e8",
   "metadata": {
    "tags": [
     "load configs"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(model_config_path, \"r\") as f:\n",
    "    lstm_model_config = json.load(f)\n",
    "\n",
    "with open(data_config_path, \"r\") as f:\n",
    "    data_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2f008",
   "metadata": {},
   "source": [
    "## Upload customized model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e26541",
   "metadata": {
    "tags": [
     "upload model"
    ]
   },
   "outputs": [],
   "source": [
    "client.upload_model(\n",
    "    package_path=package_path,\n",
    "    dataset_path=dataset_path,\n",
    "    package_name=package_name,\n",
    "    sample_model_config_path=model_config_path,\n",
    "    sample_data_config_path=data_config_path,\n",
    "    batch_size=256,\n",
    "    task=\"classification\",\n",
    "    test_only=False,\n",
    "    description=\"A custom LSTM model.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f49e93",
   "metadata": {},
   "source": [
    "## Create a Session\n",
    "\n",
    "The Quickstart guide for [creating a session](https://integrate-ai.gitbook.io/integrate.ai-user-documentation/tutorials/end-user-tutorials/model-training-with-a-sample-local-dataset#create-and-start-the-session) gives a bit more context into the paramters that are used during session creation.<br />\n",
    "For this session we are going to be using two training clients and two rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2f235",
   "metadata": {
    "tags": [
     "assign model config"
    ]
   },
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"strategy\": {\"name\": \"FedAvg\", \"params\": {}},\n",
    "    \"model\": {\"params\": lstm_model_config},\n",
    "    \"ml_task\": {\"type\": \"classification\", \"params\": {}},\n",
    "    \"optimizer\": {\"name\": \"SGD\", \"params\": {\"learning_rate\": 0.9, \"momentum\": 0.9}},\n",
    "    \"differential_privacy_params\": {\"epsilon\": 4, \"max_grad_norm\": 7},\n",
    "    \"seed\": 23,  # for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b491e3",
   "metadata": {
    "tags": [
     "start session"
    ]
   },
   "outputs": [],
   "source": [
    "session = client.create_fl_session(\n",
    "    name=\"LSTM custom model notebook\",\n",
    "    description=\"Training a custom LSTM model using a jupyter notebook.\",\n",
    "    min_num_clients=2,\n",
    "    num_rounds=5,\n",
    "    package_name=package_name,\n",
    "    model_config=model_config,\n",
    "    data_config=data_schema,\n",
    ").start()\n",
    "\n",
    "session.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b89659",
   "metadata": {},
   "source": [
    "## Start a training session using iai client\n",
    "You can use S3 URLs as `data_path` given that you AWS CLI environment is properly configured. The following environment variables have to be set for the `iai client` to be able to read S3 data locations:\n",
    "```\n",
    "export AWS_ACCESS_KEY_ID=$access_id\n",
    "export AWS_SECRET_ACCESS_KEY=$secret_id\n",
    "export AWS_SESSION_TOKEN=$token\n",
    "export AWS_REGION=ca-central-1\n",
    "```\n",
    "Replace `$var` in the above snippet with actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469aed9",
   "metadata": {
    "tags": [
     "start docker clients"
    ]
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from os.path import abspath\n",
    "\n",
    "# The path to the data you want to train should be an absolute path to the directory\n",
    "data_path = abspath(dataset_path)\n",
    "\n",
    "client_1 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {session.id} --train-path {data_path} --test-path {data_path} --batch-size 512 --approve-custom-package --client-name client-1 --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")\n",
    "client_2 = subprocess.Popen(\n",
    "    f\"iai client train --token {IAI_TOKEN} --session {session.id} --train-path {data_path} --test-path {data_path} --batch-size 512 --approve-custom-package --client-name client-2 --remove-after-complete\",\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427758d8",
   "metadata": {},
   "source": [
    "## Poll for session status\n",
    "\n",
    "You can log whatever you would like about the session during this time. For now we are logging the current round and the session status. If you want to access the logs later you can use `iai client log` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f059b",
   "metadata": {
    "tags": [
     "poll for session status"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "current_round = None\n",
    "current_status = None\n",
    "while client_1.poll() is None or client_2.poll() is None:\n",
    "    output1 = client_1.stdout.readline().decode(\"utf-8\").strip()\n",
    "    output2 = client_2.stdout.readline().decode(\"utf-8\").strip()\n",
    "    if output1:\n",
    "        print(\"silo1: \", output1)\n",
    "    if output2:\n",
    "        print(\"silo2: \", output2)\n",
    "\n",
    "    # poll for status and round\n",
    "    if current_status != session.status:\n",
    "        print(\"Session status: \", session.status)\n",
    "        current_status = session.status\n",
    "    if current_round != session.round and session.round > 0:\n",
    "        print(\"Session round: \", session.round)\n",
    "        current_round = session.round\n",
    "    time.sleep(1)\n",
    "\n",
    "output1, error1 = client_1.communicate()\n",
    "output2, error2 = client_2.communicate()\n",
    "\n",
    "print(\n",
    "    \"client_1 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_1.returncode, output1.decode(\"utf-8\"), error1.decode(\"utf-8\"))\n",
    ")\n",
    "print(\n",
    "    \"client_2 finished with return code: %d\\noutput: %s\\n  %s\"\n",
    "    % (client_2.returncode, output2.decode(\"utf-8\"), error2.decode(\"utf-8\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9bc55",
   "metadata": {},
   "source": [
    "## Session Complete!\n",
    "\n",
    "You can view the results using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0cb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = session.metrics().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48512369",
   "metadata": {},
   "source": [
    "You can view the training metrics via the .metrics() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77099b21",
   "metadata": {
    "tags": [
     "view session metrics"
    ]
   },
   "outputs": [],
   "source": [
    "display(session.metrics().as_dict())  # view all of the training metrics\n",
    "display(session.metrics().federated_metrics)  # view the loss for each round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dcdb91",
   "metadata": {},
   "source": [
    "## Trained model weights are accessible from the completed session\n",
    "Model parameters can be retrieved using the model's state_dict method. These parameters can then be saved using torch.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790d7d8",
   "metadata": {
    "tags": [
     "save model"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = session.model().as_pytorch()\n",
    "\n",
    "save_state_dict_folder = \"./saved_models\"\n",
    "# PyTorch conventional file type\n",
    "file_name = f\"{session.id}.pt\"\n",
    "os.makedirs(save_state_dict_folder, exist_ok=True)\n",
    "saved_state_dict_path = os.path.join(save_state_dict_folder, file_name)\n",
    "\n",
    "with open(saved_state_dict_path, \"w\") as f:\n",
    "    torch.save(model.state_dict(), saved_state_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529be150",
   "metadata": {},
   "source": [
    "## Load the saved model\n",
    "\n",
    "To load a model saved previously, a model object needs to be initialized first. This can be done by directly importing one of the IAI-supported packages (e.g., FFNet) or using the model class defined in a custom package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ab119",
   "metadata": {
    "tags": [
     "load model"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.sample_packages.lstmTagger.model import LSTMTagger\n",
    "\n",
    "model = LSTMTagger(embedding_dim=4, hidden_dim=3, output_size=4, vocab_size=9)\n",
    "\n",
    "# use torch.load to unpickle the state_dict\n",
    "target_state_dict = torch.load(saved_state_dict_path)\n",
    "\n",
    "model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a501f97",
   "metadata": {},
   "source": [
    "## Load the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915c254",
   "metadata": {
    "tags": [
     "create data loader"
    ]
   },
   "outputs": [],
   "source": [
    "from integrate_ai_sdk.sample_packages.lstmTagger.dataset import TaggerDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = TaggerDataset(path=dataset_path, max_len=5)\n",
    "dl = DataLoader(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4803ed3",
   "metadata": {},
   "source": [
    "## Run predictions using the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ffc78",
   "metadata": {
    "tags": [
     "predict"
    ]
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = torch.tensor([])\n",
    "y_pred = torch.tensor([])\n",
    "for x, y in dl:\n",
    "    y_true = torch.cat((y_true, y))\n",
    "\n",
    "    # The following line calculates the predicted label for a classification problem, and should be modified to fit your needs\n",
    "    pred = model(x).max(dim=1)[1]\n",
    "\n",
    "    y_pred = torch.cat((y_pred, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69c332",
   "metadata": {
    "tags": [
     "show accuracy"
    ]
   },
   "outputs": [],
   "source": [
    "f\"accuracy: {(y_pred == y_true).float().mean().item()}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd2cc32795b80d96a3961ede3063db3c5a4bd611a813fa92794506d052f542db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
